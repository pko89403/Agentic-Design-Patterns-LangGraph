{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f267df",
   "metadata": {},
   "source": [
    "# Chapter 10: Model Context Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f6b8a0",
   "metadata": {},
   "source": [
    "LLM이 효과적인 에이전트로 기능하기 위해서는, 현재 데이터를 조회하고,    \n",
    "외부 소프트웨어를 활용하는 등 **외부 환경과의 상호작용**이 필수적이다.\n",
    "\n",
    "**Model Context Protocol(MCP)** 은 이러한 요구를 충족하기 위해 설계된,  \n",
    "LLM이 외부 리소스와 연결되도록 하는 **표준화된 인터페이스**를 제공한다.  \n",
    "이 프로토콜은 LLM과 외부 시스템 간의 통합이 **일관되고 예측 가능하게** 이루어지도록 하는  \n",
    "핵심 메커니즘 역할을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f2957",
   "metadata": {},
   "source": [
    "## MCP Pattern Overview\n",
    "\n",
    "**MCP(Model Context Protocol)** 패턴은\n",
    "\n",
    "> 어떤 LLM이든, 어떤 외부 시스템·데이터베이스·툴이든  \n",
    "> 매번 커스텀 연동 없이 바로 꽂아서 연결할 수 있게 해주는  \n",
    "> **범용 어댑터(universal adapter)**\n",
    "\n",
    "Gemini, OpenAI GPT, Mixtral, Claude 같은 LLM들이  \n",
    "외부 애플리케이션, 데이터 소스, 툴과 **표준화된 방식으로 소통**할 수 있게 해 준다.\n",
    "\n",
    "\n",
    "MCP는:\n",
    "\n",
    "- LLM이 **컨텍스트를 얻고(context)**\n",
    "- **액션을 실행하며(actions)**\n",
    "- 여러 시스템과 상호작용하는 과정을\n",
    "\n",
    "단순하고 일관된 방식으로 만들어 주는  \n",
    "**범용 연결 메커니즘(universal connection mechanism)** 이라고 할 수 있다.\n",
    "\n",
    "### MCP의 기본 구조: 클라이언트–서버 아키텍처\n",
    "\n",
    "MCP는 **클라이언트–서버 아키텍처** 위에서 동작한다.\n",
    "\n",
    "- **MCP 서버(MCP server)** 는 다음과 같은 요소들을 외부로 노출한다.\n",
    "  - **Resources (리소스)**: 데이터  \n",
    "  - **Prompts / Interactive Templates (인터랙티브 템플릿)**: 프롬프트 역할을 하는 상호작용 형식  \n",
    "  - **Tools (툴)**: 실제로 실행 가능한 함수·액션\n",
    "\n",
    "- **MCP 클라이언트(MCP client)** 는 이를 소비하는 쪽으로,\n",
    "  - LLM을 호스팅하는 애플리케이션일 수도 있고  \n",
    "  - 하나의 **AI 에이전트 자체**일 수도 있다.\n",
    "\n",
    "이 표준화된 방식으로 LLM을 다양한 운영 환경에 녹여 넣는 작업의 복잡도가 **크게 감소**한다.\n",
    "\n",
    "--- \n",
    "\n",
    "### MCP의 한계 ①: “좋은 에이전틱 인터페이스”는 API 설계에 달려 있다\n",
    "\n",
    "MCP는 **“에이전틱 인터페이스(agentic interface)”를 위한 계약(contract)** 이다.  \n",
    "그리고 MCP의 실효성은 **그 아래에 있는 API가 어떻게 설계되었는지**에 따라 크게 달라진다.\n",
    "\n",
    "**에이전트가 잘 일하게 만들려면**, 기저 API가 다음과 같은 **결정론적(deterministic) 기능**을 제공해야 한다.\n",
    "\n",
    "> 기존 레거시 API를 거의 손보지 않고  \n",
    "> 그대로 MCP로 감싸기만 하는 경우\n",
    "\n",
    "예시:\n",
    "\n",
    "- 티켓 시스템 API가 “티켓 전체 내용을 하나씩 가져오기”만 지원한다고 하자.\n",
    "- 그런 API를 MCP로 그냥 감싸놓고  \n",
    "  에이전트에게 “우선순위 높은 티켓들을 요약해줘”라고 시키면,\n",
    "  - 티켓이 많아질수록 하나씩 불러와야 하므로 **느리고 비효율적**이고\n",
    "  - 누락이나 오류 가능성도 커진다.\n",
    "\n",
    "**결정론적(deterministic) 기능**\n",
    "\n",
    "- **필터링(filtering)**: 예) 우선순위가 높은 티켓만 한 번에 가져오기  \n",
    "- **정렬(sorting)**: 예) 긴급도 순으로 정렬해서 가져오기  \n",
    "\n",
    "이 점은 곧 다음을 의미한다.\n",
    "\n",
    "> 에이전트가 기존의 결정론적 워크플로우를 “마법처럼 대체”하는 것이 아니라,  \n",
    "> 오히려 **더 강력한 결정론적 지원이 있어야**  \n",
    "> 비결정론적(non-deterministic) 에이전트가 제대로 일할 수 있다는 것.\n",
    "\n",
    "### MCP의 한계 ②: 데이터 형식이 에이전트 친화적(agent-friendly)이어야 한다\n",
    "\n",
    "MCP가 **단순히 API를 감싸는 역할**만 한다면,\n",
    "그 API의 입력·출력 형식이 **에이전트가 이해하기 쉬운 형태임이 보장되지 않는다**\n",
    "\n",
    "> “연결됐다고 해서 다 유용한 건 아니다.”\n",
    "\n",
    "예시:\n",
    "\n",
    "- 어떤 문서 저장소(document store)에 대해 MCP 서버를 만들었는데,  \n",
    "  이 API가 문서를 **PDF 파일로만** 돌려준다고 하자.\n",
    "- 이 때, 이를 소비하는 에이전트가 **PDF 내용을 파싱할 수 없다면**,  \n",
    "  이 MCP 서버는 사실상 거의 쓸모가 없다.\n",
    "\n",
    "더 나은 접근 방식은:\n",
    "\n",
    "- 먼저 문서를 **텍스트 기반 형식(예: Markdown)** 으로 돌려주는 API를 설계하고  \n",
    "- 그 API를 MCP 서버로 감싸는 것이다.\n",
    "\n",
    "이렇게 해야:\n",
    "\n",
    "- 에이전트가 실제로 내용을 **읽고, 이해하고, 가공**할 수 있고\n",
    "- MCP 연결이 **“형식적으로만 연결된 상태”를 넘어, 실제로 유용한 통합**이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b46fc",
   "metadata": {},
   "source": [
    "## MCP vs. Tool Function Calling(MCP와 툴 함수 호출 비교)\n",
    "\n",
    "Model Context Protocol(MCP)와 **툴 함수 호출(tool function calling)** 은  \n",
    "모두 LLM이 외부 기능(툴 포함)에 접근하고 액션을 실행하게 해주는 메커니즘이지만,  \n",
    "접근 방식과 추상화 수준에서 차이가 있다.  \n",
    "둘 다 “텍스트 생성 그 이상”을 가능하게 하지만, 역할과 범위가 다르다.\n",
    "\n",
    "---\n",
    "\n",
    "툴 함수 호출은 **LLM이 특정, 사전에 정의된 함수(=툴)를 직접 호출하는 방식**으로 이해할 수 있다.  \n",
    "구조적으로는 **LLM ↔ 애플리케이션의 툴 처리 로직** 사이의 **일대일(one-to-one) 상호작용**에 가깝다.\n",
    "\n",
    "- LLM은 사용자의 의도를 해석해  \n",
    "    “외부 액션이 필요하다”고 판단하면,  \n",
    "    그에 맞는 **함수 호출 요청을 포맷**해서 보낸다.\n",
    "- 애플리케이션 코드는 이 요청을 받아 실제 툴/함수를 실행하고,  \n",
    "    그 **결과를 다시 LLM에게 반환**한다.\n",
    "\n",
    "이 프로세스는 **각 LLM 제공자마다 방식이 다르고, 벤더별·서비스별로 폐쇄적(proprietary)** 인 경우가 많다.\n",
    "\n",
    "---\n",
    "\n",
    "MCP는 LLM이 **외부 기능을 “발견하고(discover), 소통하며(communicate), 실제로 활용(utilize)”** 할 수 있게 해 주는 **표준화된 인터페이스**이다.  \n",
    "즉, MCP를 따르면 어떤 툴·시스템이든 **같은 규약으로 노출**되고, MCP를 이해하는 어떤 LLM이든 **같은 방식으로 접근**할 수 있다.\n",
    "\n",
    "이 프로토콜은 **오픈(open) 표준**으로 설계되어 있어,\n",
    "- 서로 다른 LLM과 툴·시스템 간에 **상호운용성(interoperability)** 을 높이고  \n",
    "- 여러 서비스를 조합해서 사용할 수 있는 **조합 가능성(composability)** 을 제공하며  \n",
    "- 한 번 만든 MCP 서버를 여러 곳에서 재사용할 수 있는 **재사용성(reusability)** 을 촉진한다.\n",
    "\n",
    "MCP는 또한 **연합(federated) 모델**을 채택한다.  \n",
    "이는 각 서비스가 **자기 영역에서 독립적으로 계속 운영**되면서도,\n",
    "- 그 위에 **MCP 호환 인터페이스만 하나 감싸면(wrapping)**  \n",
    "- 기존의 서로 다른 시스템·레거시 서비스들을 **하나의 현대적인 에이전트 생태계 안으로 편입**시킬 수 있다는 뜻이다.\n",
    "\n",
    "이렇게 MCP로 감싼 서비스들은:\n",
    "- 내부 구현은 그대로 둔 채  \n",
    "- LLM이 오케스트레이션하여 **새로운 애플리케이션과 워크플로우의 구성 요소**로 활용할 수 있다.  \n",
    "\n",
    "결과적으로,\n",
    "- **기존 핵심 시스템을 비싸게 갈아엎지 않고도**,  \n",
    "- 다양한 자산과 레거시 시스템의 가치를 살리면서  \n",
    "- 더 민첩하고(agility) 재사용 가능한 구조를 만들 수 있게 해 주는 전략이라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a245bf9",
   "metadata": {},
   "source": [
    "| 구분          | 툴 함수 호출 (Tool Function Calling)                                                | MCP (Model Context Protocol)                                                                                 |\n",
    "|---------------|----------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|\n",
    "| 표준화(Standardization) | 벤더별 독점·전용 방식으로, 형식과 구현이 LLM 제공자마다 다르다.                         | 오픈 표준 프로토콜로, 서로 다른 LLM과 툴 사이의 상호운용성을 촉진한다.                                      |\n",
    "| 범위(Scope)   | LLM이 특정, **사전에 정의된 함수 하나**의 실행을 직접 요청하는 메커니즘이다.                   | LLM과 외부 툴·시스템이 **서로를 발견하고 소통하는 전체 방식**을 정의하는 더 넓은 프레임워크이다.           |\n",
    "| 아키텍처(Architecture) | LLM과 애플리케이션의 툴 처리 로직 사이의 **1:1 상호작용 구조**이다.                     | LLM 기반 애플리케이션(클라이언트)이 여러 MCP 서버(툴)에 연결해 사용하는 **클라이언트–서버 아키텍처**이다. |\n",
    "| 발견 방식(Discovery)   | 특정 대화 맥락에서 **어떤 툴이 사용 가능한지 미리 명시적으로 알려줘야** 한다.          | 사용 가능한 툴을 **동적으로 발견**할 수 있다. MCP 클라이언트가 서버에 어떤 기능을 제공하는지 질의할 수 있다. |\n",
    "| 재사용성(Reusability)  | 툴 연동이 특정 애플리케이션과 특정 LLM에 **강하게 결합**되는 경우가 많다.              | 어떤 호환 애플리케이션에서도 접근 가능한 **재사용 가능한 독립형 MCP 서버** 개발을 장려한다.               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d158f8",
   "metadata": {},
   "source": [
    "툴 함수 호출(tool function calling)은,  \n",
    "특정 작업을 위해 **맞춤 제작된 도구 세트**를 AI에게 쥐여주는 것과 비슷하다.  \n",
    "예를 들면, 어떤 종류의 **렌치와 드라이버를 딱 정해진 용도로만 쓰는 작업장**을 떠올릴 수 있다.  \n",
    "\n",
    "반면 **MCP(Model Context Protocol)** 는  \n",
    "**범용·표준화된 전기 콘센트 시스템을 구축하는 것**에 가깝다.  \n",
    "표준을 따르는 어떤 제조사의 도구든 **꽂기만 하면 바로 쓸 수 있게 해 주는 인프라**를 제공한다.  \n",
    "이렇게 함으로써, 시간이 지날수록 다양한 도구가 추가되는  \n",
    "**동적이고 계속 확장되는 작업장(workshop)** 을 만들 수 있다.\n",
    "\n",
    "이제 MCP와 툴 함수 호출의 핵심적인 차이를 정리해 보면 다음과 같다.\n",
    "\n",
    "- **함수 호출(Function Calling)** 은  \n",
    "  - **소수의, 명확히 정의된 특정 함수들**에 직접 접근하는 메커니즘이다.\n",
    "  - 비교적 **단순한 애플리케이션**이나,  \n",
    "    사용해야 할 도구(기능) 세트가 **고정된 경우**에 적합하다.\n",
    "\n",
    "- **MCP(Model Context Protocol)** 는  \n",
    "  - LLM이 **다양한 외부 리소스, 툴, 시스템을 “발견하고 사용”** 할 수 있게 해 주는  \n",
    "    **표준화된 통신 프레임워크**이다.\n",
    "  - 여러 시스템이 서로 연결되고,  \n",
    "    상황에 따라 다양한 서비스와 상호작용해야 하는 **복잡하고 유연한 AI 환경**에서는  \n",
    "    이런 **범용 표준이 사실상 필수적인 기반**이 된다.\n",
    "\n",
    "요약하자면,  \n",
    "**함수 호출은 소수의 특정 기능에 대한 직통 통로**를 제공하고,  \n",
    "**MCP는 LLM이 광범위한 외부 자원과 능력을 찾아내고 활용할 수 있게 하는 표준화된 연결 인프라**를 제공한다.  \n",
    "단순한 서비스에는 특정 툴 몇 개면 충분하지만,  \n",
    "**복잡하고 상호 연결된 에이전트 시스템**을 만들고 싶다면 MCP 같은 보편적 표준이 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774bdc7b",
   "metadata": {},
   "source": [
    "## **Additional Considerations for MCP(MCP 추가 고려 사항)**\n",
    "\n",
    "- **Tool vs. Resource vs. Prompt:**\n",
    "\n",
    "\t세 구성요소의 역할을 명확히 이해하는 것이 중요하다.\n",
    "\n",
    "\t- **Resource(리소스):**  \n",
    "\t  정적 데이터를 의미한다.  \n",
    "\t  예: PDF 파일, 데이터베이스 레코드\n",
    "\t- **Tool(툴):**  \n",
    "\t  행동을 수행하는 실행 가능한 함수이다.  \n",
    "\t  예: 이메일 전송, API 쿼리\n",
    "\t- **Prompt(프롬프트):**  \n",
    "\t  LLM이 **리소스나 툴과 어떻게 상호작용해야 하는지**를 안내하는 템플릿이다.  \n",
    "\t  상호작용이 **구조화되고 일관되며 효과적인 방식**으로 이루어지도록 돕는다.\n",
    "\n",
    "- **Discoverability(발견 가능성):**\n",
    "\n",
    "\tMCP의 큰 장점 중 하나는, **MCP 클라이언트가 서버에 동적으로 질의하여**  \n",
    "\t어떤 툴과 리소스를 제공하는지 **실시간으로 알아낼 수 있다**는 점이다.\n",
    "\n",
    "\t- 이와 같은 **“Just-in-time 발견” 메커니즘** 덕분에,\n",
    "\t- 에이전트는 새 기능이 추가되더라도 재배포 없이  \n",
    "\t  **새로운 능력을 스스로 발견하고 활용**할 수 있다.\n",
    "\n",
    "- **Security(보안):**\n",
    "\n",
    "\t어떤 프로토콜이든 **툴과 데이터를 외부에 노출**하는 순간,  \n",
    "\t보안은 반드시 따라와야 하는 이슈이다.\n",
    "\n",
    "\t- MCP 구현 시에는 **인증(Authentication)** 과  \n",
    "\t  **인가(Authorization)** 를 통해,\n",
    "\t\t- 어떤 클라이언트가\n",
    "\t\t- 어떤 서버에\n",
    "\t\t- 어떤 액션까지 수행할 수 있는지  \n",
    "\t\t  명확히 통제해야 한다.\n",
    "\n",
    "- **Implementation(구현 난이도):**\n",
    "\n",
    "\tMCP는 오픈 스탠다드이지만,  \n",
    "\t**구현이 복잡**할 수 있다.\n",
    "\n",
    "\t- 다만, 최근에는 구현 부담을 줄여주는 도구들이 등장하고 있다.  \n",
    "\t  예를 들어:\n",
    "\t\t- Anthropic\n",
    "\t\t- FastMCP  \n",
    "\t  같은 일부 모델/서비스 제공자는 **SDK나 라이브러리**를 제공하여,\n",
    "\t\t- 보일러플레이트 코드를 많이 숨기고\n",
    "\t\t- 개발자가 보다 쉽게 MCP 클라이언트·서버를 만들고 연결할 수 있도록 돕는다.\n",
    "\n",
    "- **Error Handling(에러 처리):**\n",
    "\n",
    "\t**포괄적인 에러 처리 전략**은 MCP 설계에서 필수 요소이다.\n",
    "\n",
    "\t- 프로토콜 차원에서 다음과 같은 오류 상황을  \n",
    "\t  **어떻게 표현하고 LLM에게 전달할지** 정의해야 한다.\n",
    "\t\t- 툴 실행 실패\n",
    "\t\t- 서버 사용 불가(다운, 타임아웃 등)\n",
    "\t\t- 잘못된 요청(파라미터 오류, 권한 문제 등)\n",
    "\t- LLM이 **에러의 의미를 이해하고**,  \n",
    "\t  필요하다면 **대체 경로(다른 툴 사용, 재시도 등)** 를 시도할 수 있도록  \n",
    "\t  구조화된 에러 정보가 전달되어야 한다.\n",
    "\n",
    "- **Local vs. Remote Server(로컬 vs. 원격 서버):**\n",
    "\n",
    "\tMCP 서버는 에이전트와 **같은 머신에 로컬로 배치**할 수도 있고,  \n",
    "\t**원격 서버로 분리**해서 운영할 수도 있다.\n",
    "\n",
    "\t- **로컬 서버(local):**\n",
    "\t\t- 민감한 데이터에 대해 **보안과 성능 측면에서 유리**할 수 있다.\n",
    "\t\t- 에이전트와 MCP 서버 간 통신 지연이 적다.\n",
    "\t- **원격 서버(remote):**\n",
    "\t\t- 여러 애플리케이션이 **공유 툴 세트**를 사용할 수 있는 구조를 만들 수 있다.\n",
    "\t\t- 공통 MCP 서버를 중심으로 **확장성과 운영 편의성**을 확보할 수 있다.\n",
    "\n",
    "- **On-demand vs. Batch(온디맨드 vs. 배치 처리):**\n",
    "\n",
    "\tMCP는 **상호작용형(on-demand) 세션**과  \n",
    "\t**대규모 배치(batch) 처리** 모두를 지원할 수 있다.\n",
    "\n",
    "\t- 애플리케이션 특성에 따라  \n",
    "\t  MCP를 어떻게 호출할지(실시간/주기 실행/배치 작업 등)를 설계해야 한다.\n",
    "\n",
    "- **Transportation Mechanism(전송 메커니즘):**\n",
    "\n",
    "\tMCP는 **통신에 사용할 전송 계층(transport layer)** 도 함께 정의한다.\n",
    "\n",
    "\t- **로컬 상호작용(Local):**\n",
    "\t\t- 같은 머신 내 프로세스 간 통신에는  \n",
    "\t\t  **STDIO(표준 입력/출력) 위의 JSON-RPC** 를 사용하여  \n",
    "\t\t  가볍고 효율적인 IPC(Inter-Process Communication)를 구현한다.\n",
    "\t- **원격 상호작용(Remote):**\n",
    "\t\t- 웹 환경에 친화적인 프로토콜을 사용한다.\n",
    "\t\t\t- **Streamable HTTP**\n",
    "\t\t\t- **Server-Sent Events(SSE)**  \n",
    "\t\t- 이를 통해 **지속적이고 효율적인 클라이언트–서버 통신**을 지원하며,  \n",
    "\t\t  스트리밍 응답 등에도 잘 대응할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd11dbc",
   "metadata": {},
   "source": [
    "The Model Context Protocol uses a **client–server 모델**을 통해 정보 흐름을 표준화한다.  \n",
    "MCP에서 고급 에이전틱(agentic) 행동이 잘 작동하려면,  \n",
    "아래 구성 요소들이 **어떻게 상호작용하는지 이해하는 것**이 핵심이다.\n",
    "\n",
    "- **1. Large Language Model (LLM)**\n",
    "\n",
    "\t에이전트의 **핵심 지능**에 해당한다.  \n",
    "\t사용자의 요청을 이해하고, 수행할 계획을 세우며,  \n",
    "\t언제 외부 정보에 접근해야 하는지, 언제 어떤 액션을 실행해야 하는지를 결정한다.\n",
    "\n",
    "- **2. MCP Client:**\n",
    "\n",
    "\tLLM을 감싸고 있는 **애플리케이션 또는 래퍼(wrapper)** 로,  \n",
    "\tLLM과 MCP 서버 사이에서 **중개자 역할**을 한다.\n",
    "\n",
    "\t- LLM이 표현한 “의도(intention)”를 MCP 표준에 맞는 **정형화된 요청(formal request)** 으로 변환한다.\n",
    "\t- 어떤 MCP 서버들이 존재하는지 **발견(discover)** 하고,\n",
    "\t- 해당 서버들과 **연결(connect)** 하며,\n",
    "\t- 요청·응답을 주고받는 **통신(communicate)** 을 담당한다.\n",
    "\n",
    "- **3. MCP Server:**\n",
    "\n",
    "\t외부 세계로 향하는 **게이트웨이(gateway)** 이다.\n",
    "\n",
    "\t- MCP 클라이언트가 사용할 수 있는:\n",
    "\t\t- **Tools(툴)**  \n",
    "\t\t- **Resources(리소스)**  \n",
    "\t\t- **Prompts(프롬프트)**  \n",
    "\t\t  들을 노출한다.\n",
    "\t- 일반적으로 하나의 MCP 서버는 **특정 도메인**을 담당한다. 예를 들면:\n",
    "\t\t- 회사 내부 데이터베이스 연결\n",
    "\t\t- 이메일 서비스 연동\n",
    "\t\t- 외부 공개 API(예: 날씨 API) 래핑 등\n",
    "\n",
    "- **4. Optional Third-Party (3P) Service:**\n",
    "\n",
    "\t실제 외부 **툴·애플리케이션·데이터 소스** 자체를 의미하는 선택적 구성 요소이다.  \n",
    "\tMCP 서버가 이 3rd-party 서비스를 **관리·위임 받아 노출**하는 구조다.\n",
    "\n",
    "\t- 예:  \n",
    "\t\t- 사내 전용 데이터베이스 쿼리\n",
    "\t\t- SaaS 플랫폼과 상호작용\n",
    "\t\t- 공공 날씨 API 호출 등  \n",
    "\t- 사용자가 요청한 액션을 **실제로 수행하는 최종 엔드포인트(endpoint)** 이며,  \n",
    "\t  MCP 서버는 그 앞단에서 이를 LLM 친화적인 형태로 감싸고 중계하는 역할을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547d05c",
   "metadata": {},
   "source": [
    "MCP에서의 상호작용 흐름은 대략 다음 단계로 이루어진다.\n",
    "\n",
    "- **1. Discovery(발견 단계):**\n",
    "\n",
    "\tMCP 클라이언트는 LLM을 대신해 **MCP 서버에 질의**하여  \n",
    "\t“어떤 기능(capabilities)을 제공하는지”를 묻는다.  \n",
    "\n",
    "\t- MCP 서버는 다음과 같은 내용을 담은 **매니페스트(manifest)** 를 응답으로 돌려준다.\n",
    "\t\t- 사용 가능한 **툴(tools)** 예: `send_email`\n",
    "\t\t- 접근 가능한 **리소스(resources)** 예: `customer_database`\n",
    "\t\t- 제공하는 **프롬프트(prompts)** 목록 등  \n",
    "\n",
    "\t이 단계에서 LLM은 “이 서버가 무엇을 할 수 있는지”에 대한 **기능 지도(capability map)** 를 얻게 된다.\n",
    "\n",
    "- **2. Request Formulation(요청 구성):**\n",
    "\n",
    "\t이제 LLM은 **발견된 툴 중 하나를 실제로 사용해야 한다고 판단**한다.  \n",
    "\n",
    "\t예를 들어:\n",
    "\t- 사용자의 요청을 분석한 결과, 이메일을 보내야 한다고 결정했다고 하자.\n",
    "\t- LLM은 `send_email` 툴을 사용하기로 결정하고,\n",
    "\t- 여기에 필요한 **파라미터들**을 채운다.\n",
    "\t\t- 수신자(recipient)\n",
    "\t\t- 제목(subject)\n",
    "\t\t- 본문(body) 등  \n",
    "\n",
    "\t이렇게 해서 LLM은 **“어떤 툴을 어떤 인자로 호출할지”가 명시된 요청 객체**를 구성한다.\n",
    "\n",
    "- **3. Client Communication(클라이언트 통신):**\n",
    "\n",
    "\tMCP 클라이언트는 LLM이 구성한 요청을 받아,  \n",
    "\t이를 MCP 표준에 맞는 **정규화된 호출(standardized call)** 로 변환한다.  \n",
    "\n",
    "    해당 요청을 **적절한 MCP 서버**에 전송한다.\n",
    "\n",
    "- **4. Server Execution(서버 실행):**\n",
    "\n",
    "\tMCP 서버는 클라이언트로부터 요청을 수신한 뒤:\n",
    "\n",
    "\t1. **클라이언트 인증(Authentication)** 을 수행하고  \n",
    "\t2. 요청이 유효한지(권한, 파라미터 형식, 리소스 접근 등) **검증(Validation)** 한 다음  \n",
    "\t3. 실제 **지정된 액션을 실행**한다.\n",
    "\n",
    "\t예를 들어 이메일 전송의 경우:\n",
    "\t- 내부적으로 연결된 이메일 API의 `send()` 함수를 호출하여  \n",
    "\t  실제 메일 발송을 수행한다.\n",
    "\n",
    "- **5. Response and Context Update(응답 및 컨텍스트 업데이트):**\n",
    "\n",
    "\t액션 실행이 끝나면, MCP 서버는 결과를 **표준화된 응답 형식**으로 MCP 클라이언트에 반환한다.\n",
    "\n",
    "\t- 응답에는 보통 다음 정보가 포함된다.\n",
    "\t\t- 작업 성공 여부(success / failure)\n",
    "\t\t- 관련 출력 데이터 (예: 발송 완료된 이메일의 확인 ID, 처리 결과 값 등)\n",
    "\n",
    "\tMCP 클라이언트는 이 응답을 다시 LLM에게 전달하고,  \n",
    "\tLLM은 이를 자신의 **컨텍스트(context)** 에 반영한다.\n",
    "\n",
    "\t이렇게 업데이트된 컨텍스트를 기반으로 LLM은:\n",
    "\t- 다음 단계 계획을 세우고\n",
    "\t- 후속 액션을 결정하거나\n",
    "\t- 사용자에게 최종 응답을 생성하는 등  \n",
    "\t**전체 작업 플로우를 이어서 수행**하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc13e1a",
   "metadata": {},
   "source": [
    "## Practical Applications & Use Cases  \n",
    "MCP는 AI/LLM의 능력을 크게 확장하여 **더 유연하고 강력한 에이전트**를 만들 수 있게 한다.  \n",
    "\n",
    "- **Database Integration(데이터베이스 통합):**\n",
    "\n",
    "\tMCP를 사용하면 LLM과 에이전트가 **구조화된 데이터베이스와 자연스럽게 상호작용**할 수 있다.  \n",
    "\t예를 들어, MCP Database Toolbox를 통해 에이전트가 Google BigQuery 같은 데이터셋에 쿼리를 보내  \n",
    "\t실시간 정보를 조회하고, 보고서를 생성하거나, 레코드를 갱신하는 작업을  \n",
    "\t**자연어 명령만으로 수행**할 수 있다.\n",
    "\n",
    "- **Generative Media Orchestration(생성 미디어 오케스트레이션):**\n",
    "\n",
    "\tMCP는 에이전트가 **고급 생성형 미디어 서비스**와 연동되도록 돕는다.  \n",
    "\tMCP 기반 Genmedia 도구들을 사용하면 에이전트는 다음과 같은 워크플로를 구성할 수 있다.\n",
    "\t- 이미지 생성: Google **Imagen**\n",
    "\t- 동영상 생성: Google **Veo**\n",
    "\t- 현실감 있는 음성: Google **Chirp 3 HD**\n",
    "\t- 음악 작곡: Google **Lyria**  \n",
    "\t이를 통해 AI 애플리케이션 안에서 **동적으로 이미지, 영상, 음성, 음악을 생성·조합**하는 시나리오를 구현할 수 있다.\n",
    "\n",
    "- **External API Interaction(외부 API 연동):**\n",
    "\n",
    "\tMCP는 LLM이 **어떤 외부 API든 표준화된 방식으로 호출하고 응답을 받을 수 있는 통로**를 제공한다.  \n",
    "\t예를 들어, 에이전트는 MCP를 통해:\n",
    "\t- 실시간 날씨 정보 조회\n",
    "\t- 주가/시세 데이터 가져오기\n",
    "\t- 이메일 전송\n",
    "\t- CRM(고객 관리 시스템)과 상호작용  \n",
    "\t등을 수행할 수 있으며, 이를 통해 **언어 모델의 한계를 넘어 실제 시스템과 연결된 에이전트**로 확장된다.\n",
    "\n",
    "- **Reasoning-Based Information Extraction(추론 기반 정보 추출):**\n",
    "\n",
    "\tMCP는 LLM의 강력한 **추론 능력**을 활용해,  \n",
    "\t단순 검색을 넘어 **쿼리 의존적인 정보 추출**을 가능하게 한다.\n",
    "\n",
    "\t- 기존 검색 도구처럼 문서 전체를 통으로 반환하는 대신,  \n",
    "\t- 에이전트가 텍스트를 직접 분석하여  \n",
    "\t  사용자의 복잡한 질문에 **정확히 대응하는 문장, 조항, 수치, 그림만 발췌**할 수 있다.  \n",
    "\n",
    "- **Custom Tool Development(커스텀 툴 개발):**\n",
    "\n",
    "\t개발자는 자신만의 **커스텀 툴**을 만들고 MCP 서버(예: FastMCP 기반)를 통해 노출할 수 있다.\n",
    "\n",
    "\t- 사내 전용 함수나\n",
    "\t- 폐쇄적인 내부 시스템,\n",
    "\t- 독자적인 비즈니스 로직 등을  \n",
    "\t  LLM이 사용할 수 있는 **표준화된 MCP 툴**로 감쌀 수 있다.\n",
    "\t- 이 과정에서 LLM을 직접 수정하거나, 모델을 다시 훈련할 필요 없이  \n",
    "\t  **외부 레이어에서 기능을 확장**할 수 있다\n",
    "\n",
    "- **Standardized LLM-to-Application Communication (LLM–애플리케이션 간 표준화된 통신):**\n",
    "\n",
    "\tMCP는 LLM과 애플리케이션 사이에 **일관된 통신 레이어**를 제공한다.\n",
    "\n",
    "\t- 각 LLM 제공자별, 서비스별로 다른 인터페이스를 직접 붙이는 대신,\n",
    "\t- MCP라는 공통 표준 위에 얹어두면  \n",
    "\t  **통합 비용이 줄어들고**,  \n",
    "\t  서로 다른 LLM·호스트 애플리케이션 간 **상호운용성**이 높아진다.  \n",
    "\t그 결과, **복잡한 에이전트 시스템**을 더 쉽게 설계·구현할 수 있다.\n",
    "\n",
    "- **Complex Workflow Orchestration(복잡한 워크플로 오케스트레이션):**\n",
    "\n",
    "\t여러 MCP 툴과 데이터 소스를 조합하면,  \n",
    "\t에이전트가 **멀티 스텝과 복잡한 워크플로를 자동으로 오케스트레이션**할 수 있다.\n",
    "\n",
    "\t예를 들어, 하나의 에이전트가 다음을 연속적으로 수행할 수 있다.\n",
    "\t1. 데이터베이스에서 고객 데이터를 조회하고  \n",
    "\t2. 개인화된 마케팅 이미지를 생성하고  \n",
    "\t3. 그 고객에게 맞춤형 이메일을 작성한 뒤  \n",
    "\t4. 실제 이메일을 발송하는 것까지  \n",
    "\n",
    "\t이 모든 단계가 **각기 다른 MCP 서비스들과의 상호작용**으로 구성될 수 있다.\n",
    "\n",
    "- **IoT Device Control(IoT 디바이스 제어):**\n",
    "\n",
    "\tMCP는 LLM이 **사물인터넷(IoT) 디바이스와 상호작용**하는 것도 가능하게 한다.\n",
    "\n",
    "\t- 스마트 홈 가전 제어\n",
    "\t- 산업용 센서 모니터링 및 제어\n",
    "\t- 로봇 장비 제어 등  \n",
    "\t에이전트는 자연어 명령을 MCP를 통해 **실제 물리 시스템에 대한 제어 신호**로 변환할 수 있어,  \n",
    "\t자연어 기반 자동화 시나리오를 구축할 수 있다.\n",
    "\n",
    "- **Financial Services Automation(금융 서비스 자동화):**\n",
    "\n",
    "\t금융 도메인에서 MCP는 LLM이 다양한:\n",
    "\t- 금융 데이터 소스,\n",
    "\t- 트레이딩 플랫폼,\n",
    "\t- 컴플라이언스(규제 준수) 시스템  \n",
    "\t과 상호작용하도록 돕는다.\n",
    "\n",
    "\t에이전트는 예를 들어:\n",
    "\t- 시장 데이터를 분석하고\n",
    "\t- 거래를 실행하며\n",
    "\t- 개인화된 투자·재무 조언을 생성하고\n",
    "\t- 규제 보고를 자동화하는 작업까지 수행할 수 있다.  \n",
    "\t이 모든 과정에서 MCP는 **보안이 보장된 표준화된 커뮤니케이션 경로**를 제공한다.\n",
    "\n",
    "---\n",
    "\n",
    "### 요약\n",
    "\n",
    "Model Context Protocol(MCP)는 에이전트가:\n",
    "\n",
    "- 데이터베이스, 외부 API, 웹 리소스 등에서 **실시간 정보를 조회**하고,\n",
    "- 이메일 전송, 레코드 업데이트, 디바이스 제어 등 **실제 액션을 수행**하며,\n",
    "- 여러 소스의 데이터를 통합·처리해 **복잡한 작업을 자동화**하도록 만들어 준다.\n",
    "\n",
    "또한, 생성형 미디어 도구와의 연동까지 지원하여  \n",
    "**텍스트를 넘어 이미지·영상·음성·음악까지 다루는 리치한 AI 애플리케이션**을 구축하는 기반을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7838391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2a97645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e517271",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"filesystem\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\n",
    "                \"-y\",  # npx 설치 자동 승인\n",
    "                \"@modelcontextprotocol/server-filesystem\",\n",
    "                \".\",  # 반드시 절대 경로여야 함\n",
    "            ],\n",
    "            \"transport\": \"stdio\",\n",
    "        }\n",
    "    })\n",
    "tools = await client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725651f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='read_file', description='Read the complete contents of a file as text. DEPRECATED: Use read_text_file instead.', args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13c197880>),\n",
       " StructuredTool(name='read_text_file', description=\"Read the complete contents of a file from the file system as text. Handles various text encodings and provides detailed error messages if the file cannot be read. Use this tool when you need to examine the contents of a single file. Use the 'head' parameter to read only the first N lines of a file, or the 'tail' parameter to read only the last N lines of a file. Operates on the file as text regardless of extension. Only works within allowed directories.\", args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13aaef060>),\n",
       " StructuredTool(name='read_media_file', description='Read an image or audio file. Returns the base64 encoded data and MIME type. Only works within allowed directories.', args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13c1d6480>),\n",
       " StructuredTool(name='read_multiple_files', description=\"Read the contents of multiple files simultaneously. This is more efficient than reading files one by one when you need to analyze or compare multiple files. Each file's content is returned with its path as a reference. Failed reads for individual files won't stop the entire operation. Only works within allowed directories.\", args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbb7c40>),\n",
       " StructuredTool(name='write_file', description='Create a new file or completely overwrite an existing file with new content. Use with caution as it will overwrite existing files without warning. Handles text content with proper encoding. Only works within allowed directories.', args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbb7880>),\n",
       " StructuredTool(name='edit_file', description='Make line-based edits to a text file. Each edit replaces exact line sequences with new content. Returns a git-style diff showing the changes made. Only works within allowed directories.', args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbb7ba0>),\n",
       " StructuredTool(name='create_directory', description='Create a new directory or ensure a directory exists. Can create multiple nested directories in one operation. If the directory already exists, this operation will succeed silently. Perfect for setting up directory structures for projects or ensuring required paths exist. Only works within allowed directories.', args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbb7920>),\n",
       " StructuredTool(name='list_directory', description='Get a detailed listing of all files and directories in a specified path. Results clearly distinguish between files and directories with [FILE] and [DIR] prefixes. This tool is essential for understanding directory structure and finding specific files within a directory. Only works within allowed directories.', args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbb7e20>),\n",
       " StructuredTool(name='list_directory_with_sizes', description='Get a detailed listing of all files and directories in a specified path, including sizes. Results clearly distinguish between files and directories with [FILE] and [DIR] prefixes. This tool is useful for understanding directory structure and finding specific files within a directory. Only works within allowed directories.', args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbb7a60>),\n",
       " StructuredTool(name='directory_tree', description=\"Get a recursive tree view of files and directories as a JSON structure. Each entry includes 'name', 'type' (file/directory), and 'children' for directories. Files have no children array, while directories always have a children array (which may be empty). The output is formatted with 2-space indentation for readability. Only works within allowed directories.\", args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbb7b00>),\n",
       " StructuredTool(name='move_file', description='Move or rename files and directories. Can move files between directories and rename them in a single operation. If the destination exists, the operation will fail. Works across different directories and can be used for simple renaming within the same directory. Both source and destination must be within allowed directories.', args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbb7d80>),\n",
       " StructuredTool(name='search_files', description=\"Recursively search for files and directories matching a pattern. Searches through all subdirectories from the starting path. The search is case-insensitive and matches partial names. Returns full paths to all matching items. Great for finding files when you don't know their exact location. Only searches within allowed directories.\", args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbb7ec0>),\n",
       " StructuredTool(name='get_file_info', description='Retrieve detailed metadata about a file or directory. Returns comprehensive information including size, creation time, last modified time, permissions, and type. This tool is perfect for understanding file characteristics without reading the actual content. Only works within allowed directories.', args_schema={'$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbb7f60>),\n",
       " StructuredTool(name='list_allowed_directories', description='Returns the list of directories that this server is allowed to access. Subdirectories within these allowed directories are also accessible. Use this to understand which directories and their nested paths are available before trying to access files.', args_schema={'type': 'object', 'properties': {}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x13cbdc040>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45f73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763621039.611874 2864023 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    llm,\n",
    "    tools\n",
    ")\n",
    "\n",
    "file_response = await agent.ainvoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"현재 디렉토리에 있는 파일들을 보여줘.\"}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87e5f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='현재 디렉토리에 있는 파일들을 보여줘.', additional_kwargs={}, response_metadata={}, id='0f91a67c-86bc-4b2b-a575-9294db06893d'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'list_directory', 'arguments': '{\"path\": \".\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--dce3ef86-cca9-4032-ae34-fa28e2e1932e-0', tool_calls=[{'name': 'list_directory', 'args': {'path': '.'}, 'id': 'a762b769-5e24-42f5-989e-299213772aed', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1037, 'output_tokens': 70, 'total_tokens': 1107, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 56}}), ToolMessage(content='[FILE] .env\\n[DIR] .git\\n[FILE] .gitignore\\n[FILE] .python-version\\n[DIR] .venv\\n[FILE] Qwen_Qwen3-4B-Q4_K_M.gguf\\n[FILE] README.md\\n[DIR] __pycache__\\n[FILE] chapter0.ipynb\\n[FILE] chapter1-prompt-chaining.ipynb\\n[FILE] chapter10-model-context-protocol.ipynb\\n[FILE] chapter2-routing.ipynb\\n[FILE] chapter3-parallelization.ipynb\\n[FILE] chapter4-reflection.ipynb\\n[FILE] chapter5-tool-use.ipynb\\n[FILE] chapter6-planner.ipynb\\n[FILE] chapter7-multi-agent-collaboration.ipynb\\n[FILE] chapter8-memory-management.ipynb\\n[FILE] chapter9-learning-and-adaptation.ipynb\\n[FILE] embeddinggemma-300M-Q8_0.gguf\\n[FILE] llm.py\\n[FILE] no_think_template.jinja\\n[DIR] outputs\\n[FILE] pyproject.toml\\n[FILE] qwen3-workaround.jinja\\n[FILE] uv.lock', name='list_directory', id='ac49c5fd-512d-41d3-9a51-62d8bbac0ec5', tool_call_id='a762b769-5e24-42f5-989e-299213772aed'), AIMessage(content='현재 디렉토리에는 다음과 같은 파일과 디렉토리가 있습니다:\\n\\n**파일:**\\n*   .env\\n*   .gitignore\\n*   .python-version\\n*   Qwen_Qwen3-4B-Q4_K_M.gguf\\n*   README.md\\n*   chapter0.ipynb\\n*   chapter1-prompt-chaining.ipynb\\n*   chapter10-model-context-protocol.ipynb\\n*   chapter2-routing.ipynb\\n*   chapter3-parallelization.ipynb\\n*   chapter4-reflection.ipynb\\n*   chapter5-tool-use.ipynb\\n*   chapter6-planner.ipynb\\n*   chapter7-multi-agent-collaboration.ipynb\\n*   chapter8-memory-management.ipynb\\n*   chapter9-learning-and-adaptation.ipynb\\n*   embeddinggemma-300M-Q8_0.gguf\\n*   llm.py\\n*   no_think_template.jinja\\n*   pyproject.toml\\n*   qwen3-workaround.jinja\\n*   uv.lock\\n\\n**디렉토리:**\\n*   .git\\n*   .venv\\n*   __pycache__\\n*   outputs', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--ff03664e-61e6-4b19-bd26-b122654b4725-0', usage_metadata={'input_tokens': 1361, 'output_tokens': 272, 'total_tokens': 1633, 'input_token_details': {'cache_read': 779}})]}\n"
     ]
    }
   ],
   "source": [
    "print(file_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "826ecf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763621062.965307 2864023 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='현재 디렉토리에 있는 파일들을 보여줘.', additional_kwargs={}, response_metadata={}, id='cdbab58c-dced-4479-a7a3-db3743046e62'),\n",
       " AIMessage(content='', additional_kwargs={'function_call': {'name': 'list_directory', 'arguments': '{\"path\": \".\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--8828244b-14f5-48a4-9530-cef0b0a2ecce-0', tool_calls=[{'name': 'list_directory', 'args': {'path': '.'}, 'id': 'cda57386-b80c-4e5c-82e6-1c2016efd429', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1037, 'output_tokens': 71, 'total_tokens': 1108, 'input_token_details': {'cache_read': 730}, 'output_token_details': {'reasoning': 57}}),\n",
       " ToolMessage(content='[FILE] .env\\n[DIR] .git\\n[FILE] .gitignore\\n[FILE] .python-version\\n[DIR] .venv\\n[FILE] Qwen_Qwen3-4B-Q4_K_M.gguf\\n[FILE] README.md\\n[DIR] __pycache__\\n[FILE] chapter0.ipynb\\n[FILE] chapter1-prompt-chaining.ipynb\\n[FILE] chapter10-model-context-protocol.ipynb\\n[FILE] chapter2-routing.ipynb\\n[FILE] chapter3-parallelization.ipynb\\n[FILE] chapter4-reflection.ipynb\\n[FILE] chapter5-tool-use.ipynb\\n[FILE] chapter6-planner.ipynb\\n[FILE] chapter7-multi-agent-collaboration.ipynb\\n[FILE] chapter8-memory-management.ipynb\\n[FILE] chapter9-learning-and-adaptation.ipynb\\n[FILE] embeddinggemma-300M-Q8_0.gguf\\n[FILE] llm.py\\n[FILE] no_think_template.jinja\\n[DIR] outputs\\n[FILE] pyproject.toml\\n[FILE] qwen3-workaround.jinja\\n[FILE] uv.lock', name='list_directory', id='035a0135-0048-438c-a11f-b9df770f435c', tool_call_id='cda57386-b80c-4e5c-82e6-1c2016efd429'),\n",
       " AIMessage(content='현재 디렉토리에는 다음과 같은 파일과 디렉토리가 있습니다:\\n\\n**파일:**\\n*   .env\\n*   .gitignore\\n*   .python-version\\n*   Qwen_Qwen3-4B-Q4_K_M.gguf\\n*   README.md\\n*   chapter0.ipynb\\n*   chapter1-prompt-chaining.ipynb\\n*   chapter10-model-context-protocol.ipynb\\n*   chapter2-routing.ipynb\\n*   chapter3-parallelization.ipynb\\n*   chapter4-reflection.ipynb\\n*   chapter5-tool-use.ipynb\\n*   chapter6-planner.ipynb\\n*   chapter7-multi-agent-collaboration.ipynb\\n*   chapter8-memory-management.ipynb\\n*   chapter9-learning-and-adaptation.ipynb\\n*   embeddinggemma-300M-Q8_0.gguf\\n*   llm.py\\n*   no_think_template.jinja\\n*   pyproject.toml\\n*   qwen3-workaround.jinja\\n*   uv.lock\\n\\n**디렉토리:**\\n*   .git\\n*   .venv\\n*   __pycache__\\n*   outputs', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--beb83d89-9d65-4ab3-b145-687a2a441cec-0', usage_metadata={'input_tokens': 1361, 'output_tokens': 272, 'total_tokens': 1633, 'input_token_details': {'cache_read': 779}})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.bind_tools(tools).invoke(state[\"messages\"])\n",
    "    return {\"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "\n",
    "build_graph = StateGraph(MessagesState)\n",
    "build_graph.add_node(\"model\", call_model)\n",
    "build_graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "build_graph.add_edge(START, \"model\")\n",
    "build_graph.add_conditional_edges(\n",
    "    \"model\",\n",
    "    tools_condition\n",
    ")\n",
    "build_graph.add_edge(\"tools\", \"model\")\n",
    "\n",
    "graph = build_graph.compile()\n",
    "\n",
    "result = await graph.ainvoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"현재 디렉토리에 있는 파일들을 보여줘.\"}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "result[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b170e",
   "metadata": {},
   "source": [
    "## FastMCP\n",
    "\n",
    "FastMCP는 모델 컨텍스트 프로토콜(MCP) 서버를 빠르게 만들 수 있도록 설계된 파이썬 프레임워크\n",
    "\n",
    "```sh\n",
    "uv run fastmcp_greet.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0f7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GEMINI_MODEL_NAME = \"gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afa2e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import List, Optional\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    "    ToolMessage,\n",
    "    BaseMessage,\n",
    ")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.graph import StateGraph, START, END, add_messages\n",
    "from langgraph.types import StreamWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e232168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    # 전체 대화/툴 호출 히스토리 → memory\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    # planner가 만든 단계별 계획\n",
    "    plan: Optional[List[str]]\n",
    "    # 현재 실행 중인 단계 인덱스\n",
    "    step_index: int\n",
    "    # reflection 결과 요약\n",
    "    reflection: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ae1bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_mcp_tools():\n",
    "    mcp_url = os.getenv(\"MCP_SERVER_URL\", \"http://localhost:7777/mcp\")\n",
    "\n",
    "    client = MultiServerMCPClient(\n",
    "        {\n",
    "            \"fastmcp\": {\n",
    "                \"transport\": \"streamable_http\",\n",
    "                \"url\": mcp_url,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    tools = await client.get_tools()\n",
    "\n",
    "    tool_names = [tool.name for tool in tools]\n",
    "    print(f\"MCP 서버에서 로드된 도구들: {tool_names}\")\n",
    "\n",
    "    greet_tools = [tool for tool in tools if tool.name == \"greet\"]\n",
    "    if not greet_tools:\n",
    "        raise RuntimeError(\"MCP 서버에서 `greet` 도구를 찾을 수 없습니다.\")\n",
    "    return greet_tools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8f3b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_planner_llm() -> ChatGoogleGenerativeAI:\n",
    "    return ChatGoogleGenerativeAI(\n",
    "        model=GEMINI_MODEL_NAME,\n",
    "        api_key=GEMINI_API_KEY,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "def make_actor_llm() -> ChatGoogleGenerativeAI:\n",
    "    return ChatGoogleGenerativeAI(\n",
    "        model=GEMINI_MODEL_NAME,\n",
    "        api_key=GEMINI_API_KEY,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "def make_reflector_llm() -> ChatGoogleGenerativeAI:\n",
    "    return ChatGoogleGenerativeAI(\n",
    "        model=GEMINI_MODEL_NAME,\n",
    "        api_key=GEMINI_API_KEY,\n",
    "        temperature=0.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b7d0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"user 요청 + memory 기반으로 단계별 plan을 만든다\"\"\"\n",
    "    llm = make_planner_llm()\n",
    "\n",
    "    history_text = \"\\n\".join(\n",
    "        f\"{msg.type}: {msg.content}\" for msg in state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    당신은 MCP 서버를 통해 외부 도구를 사용하는 에이전트의 '플래너'입니다.\n",
    "\n",
    "    - MCP 서버에는 `greet(name: str) -> str` 이라는 도구가 있습니다.\n",
    "    - 이 도구는 이름을 받아 자연스러운 인사 문장을 생성합니다.\n",
    "    - 도구를 직접 호출하지는 않고, 실행 노드가 이 도구를 호출한다고 가정하세요.\n",
    "\n",
    "    대화/시스템 기록:\n",
    "    {history_text}\n",
    "\n",
    "    1. 사용자의 목표를 한 줄로 요약하고,\n",
    "    2. 그 목표를 달성하기 위해 어떤 순서로 MCP greet 도구를 활용할지\n",
    "    1~3단계의 bullet list로 계획을 세우세요.\n",
    "    3. 각 단계는 한국어로, 간단명료하게 작성하세요.\n",
    "    \"\"\"\n",
    "\n",
    "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "    print(f\"원본 응답:\\n{resp.content}\")\n",
    "\n",
    "    lines = str(resp.content).splitlines()\n",
    "    steps = [line.lstrip(\"-•* \").strip() for line in lines if line.strip().startswith((\"-\", \"•\", \"*\"))]\n",
    "    print(f\"플래너가 생성한 단계별 계획: {steps}\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"plan\": steps,\n",
    "        \"step_index\": 0,\n",
    "        \"reflection\": state.get(\"reflection\"),\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=\"계획:\\n\" + \"\\n\".join(f\"- {s}\" for s in steps)\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "async def actor_node(state: AgentState, *, mcp_greet_tool) -> AgentState:\n",
    "    \"\"\"현재 단계(plan[step_index])를 실행. 여기서는 greet MCP 도구 호출.\"\"\"\n",
    "    plan = state.get(\"plan\", [])\n",
    "    idx = state.get(\"step_index\", 0)\n",
    "\n",
    "    if idx >= len(plan):\n",
    "        return {\n",
    "            \"plan\": plan,\n",
    "            \"step_index\": idx,\n",
    "            \"reflection\": state.get(\"reflection\"),\n",
    "        }\n",
    "\n",
    "    current_step = plan[idx]\n",
    "\n",
    "    llm = make_actor_llm()\n",
    "    history_text = \"\\n\".join(\n",
    "        f\"{msg.type}: {getattr(m, 'content', '')}\" for m in state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    다음은 에이전트와 사용자의 대화 기록이다:\n",
    "\n",
    "    {history_text}\n",
    "\n",
    "    위 대화를 보고, 인사해야 할 사람의 이름만 정확히 한 단어 또는 두 단어로 출력해라.\n",
    "    이름이 없다면 'UNKNOWN'만 출력해라.\n",
    "    \"\"\"\n",
    "\n",
    "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "    name = str(resp.content).strip()\n",
    "\n",
    "    if name.upper() == \"UNKNOWN\":\n",
    "        greet_result = \"이름을 알 수 없어 인사를 할 수 없습니다.\"\n",
    "    else:\n",
    "        greet_result = await mcp_greet_tool.ainvoke({\"name\": name})\n",
    "\n",
    "    tool_msg = ToolMessage(\n",
    "        content=str(greet_result),\n",
    "        tool_call_id=\"mcp-greet-call\",\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"plan\": plan,\n",
    "        \"step_index\": idx + 1,\n",
    "        \"reflection\": state.get(\"reflection\"),\n",
    "        \"messages\": [\n",
    "            AIMessage(content=f\"현재 단계 실행: {current_step}\\n대상 이름: {name}\"),\n",
    "            tool_msg,\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def reflector_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"툴 결과를 보고 인사가 자연스러운지, 개선할 점이 있는지 reflection.\"\"\"\n",
    "    llm = make_reflector_llm()\n",
    "\n",
    "    tool_msgs = [m for m in state[\"messages\"] if isinstance(m, ToolMessage)]\n",
    "    if not tool_msgs:\n",
    "        return {\n",
    "            \"plan\": state.get(\"plan\"),\n",
    "            \"step_index\": state.get(\"step_index\", 0),\n",
    "            \"reflection\": state.get(\"reflection\"),\n",
    "        }\n",
    "\n",
    "    last_tool = tool_msgs[-1]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    다음은 에이전트가 MCP greet 도구를 사용해 생성한 인사 메시지이다:\n",
    "\n",
    "    \\\"\\\"\\\"{last_tool.content}\\\"\\\"\\\"\n",
    "\n",
    "    1. 자연스러운 한국어 인사인가?\n",
    "    2. 더 나은 버전이 있다면 한 줄로 다시 적어라.\n",
    "    3. 충분히 괜찮다면 'OK'만 출력해라.\n",
    "    \"\"\"\n",
    "\n",
    "    resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "    reflection = str(resp.content).strip()\n",
    "\n",
    "    new_messages: List[BaseMessage] = []\n",
    "    if reflection != \"OK\":\n",
    "        new_messages = new_messages.append(\n",
    "            AIMessage(content=f\"[Reflection 개선안]\\n{reflection}\")\n",
    "        )\n",
    "\n",
    "    if new_messages:\n",
    "        return {\n",
    "            \"plan\": state.get(\"plan\"),\n",
    "            \"step_index\": state.get(\"step_index\", 0),\n",
    "            \"reflection\": reflection,\n",
    "            \"messages\": new_messages,\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"plan\": state.get(\"plan\"),\n",
    "            \"step_index\": state.get(\"step_index\", 0),\n",
    "            \"reflection\": \"OK\",\n",
    "        }\n",
    "\n",
    "def should_reflect_or_end(state: AgentState) -> str:\n",
    "    \"\"\"reflection 이후 그래프를 종료할지 결정.\"\"\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cda0ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def build_graph():\n",
    "    greet_tool = await load_mcp_tools()\n",
    "\n",
    "    async def _actor_node_wrapped(state: AgentState) -> AgentState:\n",
    "        return await actor_node(state, mcp_greet_tool=greet_tool)\n",
    "\n",
    "    graph = StateGraph(AgentState)\n",
    "\n",
    "    graph.add_node(\"planner\", planner_node)\n",
    "    graph.add_node(\"actor\", _actor_node_wrapped)\n",
    "    graph.add_node(\"reflector\", reflector_node)\n",
    "\n",
    "    graph.add_edge(START, \"planner\")\n",
    "    graph.add_edge(\"planner\", \"actor\")\n",
    "    graph.add_edge(\"actor\", \"reflector\")\n",
    "    graph.add_conditional_edges(\n",
    "        \"reflector\",\n",
    "        should_reflect_or_end,\n",
    "        {END: END}\n",
    "    )\n",
    "\n",
    "    return graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0dbf3ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP 서버에서 로드된 도구들: ['greet']\n",
      "원본 응답:\n",
      "1.  **사용자의 목표:** 사용자에게 이름으로 인사하기.\n",
      "\n",
      "2.  **MCP greet 도구 활용 계획:**\n",
      "    *   사용자 발화에서 이름 '철수'를 추출합니다.\n",
      "    *   추출한 이름('철수')을 인자로 사용하여 MCP 서버의 `greet` 도구를 호출합니다.\n",
      "    *   도구의 반환 값을 사용자에게 응답으로 전달합니다.\n",
      "플래너가 생성한 단계별 계획: [\"사용자 발화에서 이름 '철수'를 추출합니다.\", \"추출한 이름('철수')을 인자로 사용하여 MCP 서버의 `greet` 도구를 호출합니다.\", '도구의 반환 값을 사용자에게 응답으로 전달합니다.']\n",
      "human: 안녕, 내 이름은 철수야. 반가워!\n",
      "\n",
      "ai: 계획:\n",
      "- 사용자 발화에서 이름 '철수'를 추출합니다.\n",
      "- 추출한 이름('철수')을 인자로 사용하여 MCP 서버의 `greet` 도구를 호출합니다.\n",
      "- 도구의 반환 값을 사용자에게 응답으로 전달합니다.\n",
      "\n",
      "ai: 현재 단계 실행: 사용자 발화에서 이름 '철수'를 추출합니다.\n",
      "대상 이름: 철수\n",
      "\n",
      "tool: Hello, 철수! Welcome to FastMCP.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = await build_graph()\n",
    "\n",
    "init_state: AgentState = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"안녕, 내 이름은 철수야. 반가워!\")\n",
    "    ],\n",
    "    \"plan\": None,\n",
    "    \"step_index\": 0,\n",
    "    \"reflection\": None,\n",
    "}\n",
    "\n",
    "result = await graph.ainvoke(init_state)\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type}: {msg.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61b43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63f246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic-Design-Patterns-LanGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
